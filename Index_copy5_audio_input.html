<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice-Powered Chat with PolyCam</title>

  <style>

    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      /* Prevent horizontal scrollbar */
      overflow-x: hidden;
      overflow-y: hidden;
    }

    /* Container holds the iframe and fullscreen button */
    #container {
      position: relative;
      width: 100%;
      height: 100%;
    }

    /* Fullscreen button styling - positioned bottom-right */
    #fullscreenBtn {
      position: absolute;
      bottom: 10px;
      right: 18px;
      z-index: 100;
      background-color: rgba(255, 255, 255, 0.185);
      color: #fff;
      border: none;
      padding: 5px;
      cursor: pointer;
      font-size: 0px;
      border-radius: 4px;
    }

    /* Make the iframe fill the container */
    iframe {
      width: 100%;
      height: 100%;
      border: none;
      z-index: 1; 
      /* æ–°å¢çš„é»‘ç™½æ»¤é•œ */
      animation: artFilterCycle 35s infinite ease-in-out;
    }
    
    @keyframes videoBrightness {
      0% {
        filter: opacity(0%);
      }
      50% {
        filter: opacity(100%);
      }
      100% {
        filter: opacity(0%);
      }
    }

    @keyframes artFilterCycle {
      0% {
        filter: grayscale(0%) sepia(0%) contrast(100%) brightness(100%);
      }
      25% {
        filter: grayscale(80%) sepia(30%) contrast(110%) brightness(90%);
      }
      50% {
        filter: grayscale(100%) sepia(60%) contrast(120%) brightness(80%);
      }
      75% {
        filter: grayscale(60%) sepia(40%) contrast(115%) brightness(85%);
      }
      100% {
        filter: grayscale(0%) sepia(0%) contrast(100%) brightness(100%);
      }
    }

    /* æ–°çš„æ–‡å­—è§†é¢‘å®¹å™¨æ ·å¼ */
    #videoTextContainer {
      position: absolute;
      top: 0px;
      right: -200px;
      width: 900px;
      z-index: 10;
      pointer-events: none;
      /* ä½¿ç”¨æ··åˆæ¨¡å¼æ»¤é™¤é»‘è‰²èƒŒæ™¯ */
      mix-blend-mode: screen;
    }

    #textVideo {
      width: 100%;
      height: 100%;
      object-fit: contain;
    }

    /* Default positioning for the video container */
    #videoContainer {
      position: absolute;
      left: 100px;
      bottom: 100px;
      width: 480px;
      height: 200px;
      overflow: hidden;
      outline: 0px solid #ffffff; 
      outline-offset: 0;
      box-shadow: 0 0 10px 10px rgba(0, 0, 0, 0.526);
    }
    
    /* When the viewport is short, force the video container to be at least 100px from the top */
    @media (max-height: 420px) {
      #videoContainer {
        top: 100px;
      }
    }
    
    /* Video styling */
    #overlayVideo {
      width: 100%;
      height: 100%;
      object-fit: cover;
      object-position: center center;
      display: block;
    }

    /* ä¿®æ”¹åçš„èŠå¤©å®¹å™¨æ ·å¼ */
    .chat-container {
        position: absolute;
        left: 100px;
        bottom: 320px;
        width: 480px;
        height: 300px; /* å›ºå®šé«˜åº¦æ›¿ä»£max-height */
        background: rgba(0, 0, 0, 0);
        color: white;
        overflow: hidden;
        font-family: system-ui, -apple-system, sans-serif;
        display: flex; /* æ–°å¢flexå¸ƒå±€ */
        flex-direction: column; /* å‚ç›´æ’åˆ— */
    }

    .chat-history {
      height:288px;
      overflow-y: auto;
      text-align: left;
      padding-bottom: 45px;
    }

    .chat-history::-webkit-scrollbar {
      width: 8px;
      height: 8px;
      background: transparent;
    }

    .chat-history::-webkit-scrollbar-thumb {
      background: rgba(255, 255, 255, 0.3);
      border-radius: 4px;
      transition: box-shadow 0.3s ease; 
    }

    /* æ‚¬åœçŠ¶æ€ */
    .chat-history::-webkit-scrollbar-thumb:hover {
      background: rgba(255, 255, 255, 0.6); /* æ›´æ˜æ˜¾çš„ç™½è‰² */
    }

    #transcription-status {
      color: #aaa;
      font-style: italic;
      margin-bottom: 10px;
    }

    /* ä¿®æ”¹åçš„æŒ‰é’®å®šä½ */
    #toggle-mic-btn {
      position: relative; /* æ”¹ä¸ºç›¸å¯¹å®šä½ */
      left: 0;
      bottom: 0;
      margin-top: auto; /* è‡ªåŠ¨æ¨åˆ°å®¹å™¨åº•éƒ¨ */
      width: min-content;
      min-width: 120px; /* æœ€å°å®½åº¦ä¿è¯æ–‡å­—ä¸æ¢è¡Œ */
      white-space: nowrap; /* é˜²æ­¢æ–‡å­—æ¢è¡Œ */
      z-index: 10;
      background-color: rgba(255, 255, 255, 0.6);
      color: #fff;
      border: none;
      padding: 8px 16px;
      border-radius: 0px;
      font-size: 12px;
      cursor: pointer;
    }

  </style>

</head>

<body>

  <div id="container">

    <button id="fullscreenBtn">
      <img src="./fullscreen-svgrepo-com.svg" style="width: 30px; height:30px;">
    </button>

    <!-- Polycam Embed Code -->
    <iframe src="https://poly.cam/capture/fca35082-b2b5-45ca-b137-b8845bbc852a/embed" 
            allow="camera; microphone; fullscreen; accelerometer; gyroscope; magnetometer; vr; xr-spatial-tracking">
    </iframe>

    <div id="videoTextContainer">
      <video id="textVideo" src="TDMovieOut.1.mp4" autoplay muted loop preload="auto" playsinline></video>
    </div>

    <!-- Overlay Video -->
    <div id="videoContainer">
      <video id="overlayVideo" src="./1.0.mp4" autoplay muted loop></video>
    </div>

    <!-- æ–°å¢èŠå¤©å®¹å™¨ -->
    <div class="chat-container">
      <div class="chat-history" id="chat-history"></div>
      <!-- New voice interface elements -->
      <div id="transcription-status">
        <!-- Real-time transcription will appear here -->
      </div>
      <button id="toggle-mic-btn">
        ğŸ™ï¸ Start Listening
      </button>
    </div>
  </div>

  <script>
    // åœ¨é¡µé¢åŠ è½½åå¼ºåˆ¶è®¾ç½®å¾ªç¯
    window.addEventListener('load', () => {
      const videos = document.querySelectorAll('video');
      videos.forEach(video => {
        video.loop = true; // æ˜¾å¼è®¾ç½®å¾ªç¯
        
        // å…¼å®¹æ€§å¤„ç†
        video.addEventListener('ended', () => {
          video.currentTime = 0;
          video.play();
        });
      });
    });
  </script>

  <script>
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const container = document.getElementById('container');

    // ======== æ–°å¢åŠ¨ç”»æ§åˆ¶å™¨ä»£ç  ========
    function initVideoAnimation() {
      const video = document.getElementById('textVideo');
      const container = document.getElementById('videoTextContainer');

      const setAnimation = () => {
        if(video.duration > 0) {
          const duration = video.duration;
          
          // å¼ºåˆ¶é‡ç»˜æŠ€å·§
          container.style.animation = 'none';
          void container.offsetHeight; // è§¦å‘ reflow
          
          container.style.animation = 
            `videoBrightness ${duration}s infinite ease-in-out`;
        }
      };

      // äº‹ä»¶ç›‘å¬ä¼˜åŒ–ç‰ˆæœ¬
      const events = ['loadedmetadata', 'canplay', 'playing'];
      events.forEach(e => video.addEventListener(e, setAnimation));

      // Safari å…¼å®¹æ–¹æ¡ˆ
      let loadAttempts = 0;
      const safariCheck = setInterval(() => {
        if(video.readyState > 0 || loadAttempts++ > 5) {
          setAnimation();
          clearInterval(safariCheck);
        }
      }, 500);
    }

    // åˆå§‹åŒ–æ—¶æœºæ§åˆ¶
    if(document.readyState === 'complete') {
      initVideoAnimation();
    } else {
      window.addEventListener('load', initVideoAnimation);
      document.addEventListener('DOMContentLoaded', initVideoAnimation);
    }

    fullscreenBtn.addEventListener('click', () => {
      if (!document.fullscreenElement) {
        container.requestFullscreen().catch(err => {
          console.error(`Error attempting to enable full-screen mode: ${err.message}`);
        });
      } else {
        document.exitFullscreen();
      }
    });

  </script>

  <!-- Include Socket.io client library for WebSocket communication -->
  <script src="/socket.io/socket.io.js"></script>

  <script>

    // Check browser support for Web Speech API
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      alert("Sorry, your browser doesn't support speech recognition. Please use Chrome/Edge, etc.");
    } else {
      const recognition = new SpeechRecognition();
      recognition.continuous = true;       // keep listening until stopped
      recognition.interimResults = true;   // show real-time interim results
      recognition.lang = "en-US";          // language for recognition

      const socket = io();  // connect to Node.js server via WebSocket
      let interimBuffer = ""; // æ·»åŠ è¿™ä¸€è¡Œ
      const chatHistory = document.getElementById('chat-history');
      const statusDiv   = document.getElementById('transcription-status');
      const micBtn      = document.getElementById('toggle-mic-btn');
      let listening = false;  // to track if mic is active

      // ä¿®æ”¹åçš„appendMessageå‡½æ•°
      function appendMessage(sender, text) {
        const msgDiv = document.createElement('div');
        msgDiv.className = sender === 'user' ? 'user-message' : 'assistant-message';
        msgDiv.textContent = text;
        
        // åœ¨æ·»åŠ å…ƒç´ å‰è·å–å½“å‰æ»šåŠ¨çŠ¶æ€
        const container = chatHistory;
        const wasAtBottom = container.scrollHeight - container.clientHeight <= container.scrollTop + 1;

        chatHistory.appendChild(msgDiv);

        // ä½¿ç”¨åŒRAFç¡®ä¿DOMæ›´æ–°å®Œæˆ
        requestAnimationFrame(() => {
          requestAnimationFrame(() => {
            // å¼ºåˆ¶æ»šåŠ¨åˆ°åº•éƒ¨
            container.scrollTop = container.scrollHeight;
                
            // å¦‚æœå½“å‰ä¸åœ¨åº•éƒ¨ï¼Œæ·»åŠ è§†è§‰æç¤º
            if (!wasAtBottom) {
              container.style.boxShadow = 'inset 0 -5px 10px rgba(255,255,255,0.3)';
              setTimeout(() => {
                container.style.boxShadow = 'none';
              }, 500);
            }
          });
        });
      }

      micBtn.addEventListener('click', async () => {
        try {
          if (!listening) {
            // æ˜¾å¼è¯·æ±‚éº¦å…‹é£æƒé™
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
      
            recognition.start();
            micBtn.textContent = "ğŸ”´ Stop Listening";
            statusDiv.textContent = "Listening...";
            listening = true;
          } else {
            recognition.stop();
            micBtn.textContent = "ğŸ™ï¸ Start Listening";
            statusDiv.textContent = "";
            listening = false;
          }
        } catch (err) {
          console.error('éº¦å…‹é£è®¿é—®é”™è¯¯:', err);
          statusDiv.textContent = "è¯·å…è®¸éº¦å…‹é£è®¿é—®";
          micBtn.textContent = "ğŸ™ï¸ Start Listening";
          listening = false;
        }
      });

      // å¢åŠ è¯­éŸ³è¯†åˆ«é”™è¯¯å¤„ç†
      recognition.onerror = (event) => {
        console.error('è¯†åˆ«é”™è¯¯:', event.error);
        if (event.error === 'not-allowed') {
          statusDiv.textContent = 'è¯·å…è®¸éº¦å…‹é£è®¿é—®';
        }
        listening = false;
        micBtn.textContent = "ğŸ™ï¸ Start Listening";
      };

      // ä¿®æ”¹åçš„å˜é‡
      let confirmedSegments = [];  // å­˜å‚¨æ‰€æœ‰å·²ç¡®è®¤çš„æ®µè½
      let currentDraft = "";       // å½“å‰ä¸´æ—¶è‰ç¨¿
      let silenceTimer = null;
      const SILENCE_TIMEOUT = 5000;

      // ==== æ–°å¢é˜²æŠ–å‡½æ•° ====
      const debounce = (func, delay) => {
        let timer;
        return (...args) => {
          clearTimeout(timer);
          timer = setTimeout(() => func(...args), delay);
        };
      };

      const debouncedSubmit = debounce((text) => {
        handleFinalTranscript(text);
      }, 1000); // 1ç§’é˜²æŠ–çª—å£

      // ç»Ÿä¸€æäº¤å‡½æ•°ï¼ˆéœ€è¦æ›¿æ¢æ—§ç‰ˆæœ¬ï¼‰
      function commitFinalTranscript() {
        // åˆå¹¶æ‰€æœ‰å†…å®¹
        const fullText = confirmedSegments.length > 0 
          ? `${confirmedSegments.join(". ")} ${currentDraft}`.trim()
          : currentDraft;

        // é˜²æŠ–æäº¤ï¼ˆå¤ç”¨å·²æ·»åŠ çš„é˜²æŠ–å‡½æ•°ï¼‰
        debouncedSubmit(fullText); 

        // æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
        confirmedSegments = [];
        currentDraft = "";
        clearTimeout(silenceTimer);
      }

      function handleFinalTranscript(rawText) {
        // ==== æ–°å¢æ™ºèƒ½å»é‡é€»è¾‘ ====
        const removeRepeatedPhrases = (text) => {
          const phraseMap = new Map();
          return text.split(/[,.]/g)
            .map(phrase => phrase.trim())
            .filter(phrase => {
              const key = phrase.toLowerCase();
              return !phraseMap.has(key) && phraseMap.set(key, true);
            })
            .join(". ");
        };

        const cleanText = rawText
          .replace(/(\b\w+\b)(\s+\1\b)+/gi, "$1")
          .replace(/\s{2,}/g, " ")
          .replace(/(\S)([,.])(\S)/g, "$1$2 $3")
          .trim();

        const finalText = removeRepeatedPhrases(cleanText);
    
        if (finalText) {
          appendMessage('user', finalText);
          socket.emit('transcript', finalText);
          statusDiv.textContent = "Submitted âœ“";
          // æ–°å¢ï¼šæäº¤åå¼ºåˆ¶æ¸…ç©ºç¼“å­˜
          confirmedSegments = []; // éœ€è¦å…ˆåœ¨é¡¶éƒ¨å£°æ˜è¿™ä¸ªå˜é‡
          currentDraft = "";
        }
      }

      let debugCount = 0;

      recognition.onresult = (event) => {
    
        console.log(`å¤„ç†ç»“æœ #${++debugCount}`, event);

        clearTimeout(silenceTimer); // å¿…é¡»é¦–å…ˆæ¸…é™¤æ—§è®¡æ—¶å™¨

        const validResults = Array.from(event.results)
          .slice(event.resultIndex)
          .filter(result => result[0].transcript.trim() !== "");

        let hasNewFinal = false;
    
        confirmedSegments = [];
        
        validResults.forEach(result => {
          const text = result[0].transcript.trim();
          if (result.isFinal) {
            if (!confirmedSegments.includes(text)) {
              confirmedSegments.push(text);
              hasNewFinal = true;
            }
          } else {
            currentDraft = text; // éœ€è¦å…ˆåœ¨é¡¶éƒ¨å£°æ˜ let currentDraft = "";
          }
        });

        // æ„å»ºå®Œæ•´å†…å®¹
        const fullText = confirmedSegments.length > 0 
          ? `${confirmedSegments.join(". ")} ${currentDraft}`.trim()
          : currentDraft;

        // æ›´æ–°æ˜¾ç¤º
        statusDiv.textContent = hasNewFinal 
          ? `å·²ç¡®è®¤æ®µè½: ${confirmedSegments.join(" | ")}`
          : currentDraft 
            ? `è¾“å…¥ä¸­: ${currentDraft}`
            : "";

        // é‡ç½®è®¡æ—¶å™¨
        if (fullText) {
          silenceTimer = setTimeout(() => {
            debouncedSubmit(fullText); 
            confirmedSegments = []; // æäº¤åæ¸…ç©ºå†å²
            currentDraft = "";
          }, 5000);
        }
      };

      // Restart recognition automatically if it stops (for continuous listening)
      recognition.onend = () => {
        if (listening) {
          // If the mic is still supposed to be on, restart listening (user paused speaking)
          recognition.start();
        }
      };

      // éœ€è¦ä¿®æ”¹çš„é”™è¯¯å¤„ç†ä»£ç æ®µ
      recognition.onerror = (err) => {
        console.error("Speech recognition error:", err);
        clearTimeout(silenceTimer);
    
        // æ–°å¢é”™è¯¯ç±»å‹è¿‡æ»¤
        const ignorableErrors = [
          'no-speech',         // æ— è¯­éŸ³è¾“å…¥
          'audio-capture',     // éŸ³é¢‘æ•è·é—®é¢˜
          'network'            // ç½‘ç»œé”™è¯¯
        ];

        if (listening) {
          // å¯¹å¯å¿½ç•¥é”™è¯¯ä¸æ˜¾ç¤ºæç¤º
          if (!ignorableErrors.includes(err.error)) {
            statusDiv.textContent = "âš ï¸ Mic error, restarting...";
          }
        
          // ä¼˜åŒ–é‡å¯ç­–ç•¥
          const retry = () => {
            recognition.stop();  // å…ˆæ­£å¸¸åœæ­¢
            setTimeout(() => {
              recognition.start().catch(error => {
                console.log('é‡å¯å¤±è´¥:', error);
              });
            }, 500);
          };
        
          // æ ¹æ®é”™è¯¯ç±»å‹å¤„ç†
          switch(err.error) {
            case 'no-speech':
              // æ— è¯­éŸ³æ—¶ä¸é‡å¯
              break;
            case 'network':
              retry();
              break;
            default:
              setTimeout(retry, 1000);
          }
        }
      };

      // Receive AI assistant responses from the server and display them
      socket.on('assistantResponse', (message) => {
        appendMessage('assistant', message);
      });
    }

  </script>

</body>

</html>