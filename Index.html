<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice-Powered Chat with PolyCam</title>

  <style>

    html, body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      /* Prevent horizontal scrollbar */
      overflow-x: hidden;
      overflow-y: hidden;
    }

    /* Container holds the iframe and fullscreen button */
    #container {
      position: relative;
      width: 100%;
      height: 100%;
    }

    /* Fullscreen button styling - positioned bottom-right */
    #fullscreenBtn {
      position: absolute;
      bottom: 10px;
      right: 18px;
      z-index: 100;
      background-color: rgba(255, 255, 255, 0.185);
      color: #fff;
      border: none;
      padding: 5px;
      cursor: pointer;
      font-size: 0px;
      border-radius: 4px;
    }

    /* Make the iframe fill the container */
    iframe {
      width: 100%;
      height: 100%;
      border: none;
      z-index: 1; 
      /* 新增的黑白滤镜 */
      animation: artFilterCycle 35s infinite ease-in-out;
    }
    
    @keyframes videoBrightness {
      0% {
        filter: opacity(0%);
      }
      50% {
        filter: opacity(100%);
      }
      100% {
        filter: opacity(0%);
      }
    }

    @keyframes artFilterCycle {
      0% {
        filter: grayscale(0%) sepia(0%) contrast(100%) brightness(100%);
      }
      25% {
        filter: grayscale(80%) sepia(30%) contrast(110%) brightness(90%);
      }
      50% {
        filter: grayscale(100%) sepia(60%) contrast(120%) brightness(80%);
      }
      75% {
        filter: grayscale(60%) sepia(40%) contrast(115%) brightness(85%);
      }
      100% {
        filter: grayscale(0%) sepia(0%) contrast(100%) brightness(100%);
      }
    }

    /* 新的文字视频容器样式 */
    #videoTextContainer {
      position: absolute;
      top: 0px;
      right: -200px;
      width: 900px;
      z-index: 10;
      pointer-events: none;
      /* 使用混合模式滤除黑色背景 */
      mix-blend-mode: screen;
    }

    #textVideo {
      width: 100%;
      height: 100%;
      object-fit: contain;
    }

    /* Default positioning for the video container */
    #videoContainer {
      position: absolute;
      left: 100px;
      bottom: 100px;
      width: 480px;
      height: 200px;
      overflow: hidden;
      outline: 0px solid #ffffff; 
      outline-offset: 0;
      box-shadow: 0 0 10px 10px rgba(0, 0, 0, 0.526);
    }
    
    /* When the viewport is short, force the video container to be at least 100px from the top */
    @media (max-height: 420px) {
      #videoContainer {
        top: 100px;
      }
    }
    
    /* Video styling */
    #overlayVideo {
      width: 100%;
      height: 100%;
      object-fit: cover;
      object-position: center center;
      display: block;
    }

    /* 修改后的聊天容器样式 */
    .chat-container {
        position: absolute;
        left: 100px;
        bottom: 320px;
        width: 480px;
        height: 300px; /* 固定高度替代max-height */
        background: rgba(0, 0, 0, 0);
        color: white;
        overflow: hidden;
        font-family: system-ui, -apple-system, sans-serif;
        display: flex; /* 新增flex布局 */
        flex-direction: column; /* 垂直排列 */
    }

    .chat-history {
      height:288px;
      overflow-y: auto;
      text-align: left;
      padding-bottom: 45px;
      font-size: 10.5px;
    }

    .chat-history::-webkit-scrollbar {
      width: 8px;
      height: 8px;
      background: transparent;
    }

    .chat-history::-webkit-scrollbar-thumb {
      background: rgba(255, 255, 255, 0.3);
      border-radius: 4px;
      transition: box-shadow 0.3s ease; 
    }

    /* 悬停状态 */
    .chat-history::-webkit-scrollbar-thumb:hover {
      background: rgba(255, 255, 255, 0.6); /* 更明显的白色 */
    }

    #transcription-status {
      color: #aaa;
      font-style: italic;
      margin-bottom: 10px;
      font-size: 10.5px;
    }

    /* 修改后的按钮定位 */
    #toggle-mic-btn {
      position: relative; /* 改为相对定位 */
      left: 0;
      bottom: 0;
      margin-top: auto; /* 自动推到容器底部 */
      width: min-content;
      min-width: 120px; /* 最小宽度保证文字不换行 */
      white-space: nowrap; /* 防止文字换行 */
      z-index: 10;
      background-color: rgba(255, 255, 255, 0.6);
      color: #fff;
      border: none;
      padding: 8px 16px;
      border-radius: 0px;
      font-size: 12px;
      cursor: pointer;
    }

    #liveStreamContainer {
      position: absolute;
      width: 750px;
      height: 750px;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 20; /* 确保它位于其他元素之上 */
    }

    /* Live stream video styling */
    .streamVideo {
      width: 100%;
      height: 100%;
      border-radius: 50%;
      overflow: hidden;
      background: #ffffff;
      z-index: 30;
    }

  </style>

</head>

<body>

  <div id="container">

    <button id="fullscreenBtn">
      <img src="./fullscreen-svgrepo-com.svg" style="width: 30px; height:30px;">
    </button>

    <!-- Polycam Embed Code -->
    <iframe src="https://poly.cam/capture/fca35082-b2b5-45ca-b137-b8845bbc852a/embed" 
            allow="camera; microphone; fullscreen; accelerometer; gyroscope; magnetometer; vr; xr-spatial-tracking">
    </iframe>

    <div id="videoTextContainer">
      <video id="textVideo" src="TDMovieOut.1.mp4" autoplay muted loop preload="auto" playsinline></video>
    </div>

    <!-- Overlay Video -->
    <div id="videoContainer">
      <video id="overlayVideo" src="./1.0.mp4" autoplay muted loop></video>
    </div>

    <!-- 新增聊天容器 -->
    <div class="chat-container">
      <div class="chat-history" id="chat-history"></div>
      <!-- New voice interface elements -->
      <div id="transcription-status">
        <!-- Real-time transcription will appear here -->
      </div>
      <button id="toggle-mic-btn">
        🎙️ Start Listening
      </button>
    </div>

    <!-- Insert the live stream video element where desired -->
    <div id="liveStreamContainer">
      <video class="streamVideo" autoplay muted playsinline></video>
    </div>

  </div>

  <script>
    // 在页面加载后强制设置循环
    window.addEventListener('load', () => {
      const videos = document.querySelectorAll('video');
      videos.forEach(video => {
        video.loop = true; // 显式设置循环
        
        // 兼容性处理
        video.addEventListener('ended', () => {
          video.currentTime = 0;
          video.play();
        });
      });
    });
  </script>

  <script>
    const fullscreenBtn = document.getElementById('fullscreenBtn');
    const container = document.getElementById('container');

    // ======== 新增动画控制器代码 ========
    function initVideoAnimation() {
      const video = document.getElementById('textVideo');
      const container = document.getElementById('videoTextContainer');

      const setAnimation = () => {
        if(video.duration > 0) {
          const duration = video.duration;
          
          // 强制重绘技巧
          container.style.animation = 'none';
          void container.offsetHeight; // 触发 reflow
          
          container.style.animation = 
            `videoBrightness ${duration}s infinite ease-in-out`;
        }
      };

      // 事件监听优化版本
      const events = ['loadedmetadata', 'canplay', 'playing'];
      events.forEach(e => video.addEventListener(e, setAnimation));

      // Safari 兼容方案
      let loadAttempts = 0;
      const safariCheck = setInterval(() => {
        if(video.readyState > 0 || loadAttempts++ > 5) {
          setAnimation();
          clearInterval(safariCheck);
        }
      }, 500);
    }

    // 初始化时机控制
    if(document.readyState === 'complete') {
      initVideoAnimation();
    } else {
      window.addEventListener('load', initVideoAnimation);
      document.addEventListener('DOMContentLoaded', initVideoAnimation);
    }

    fullscreenBtn.addEventListener('click', () => {
      if (!document.fullscreenElement) {
        container.requestFullscreen().catch(err => {
          console.error(`Error attempting to enable full-screen mode: ${err.message}`);
        });
      } else {
        document.exitFullscreen();
      }
    });

  </script>

  <!-- Include Socket.io client library for WebSocket communication -->
  <script src="/socket.io/socket.io.js"></script>

  <script>
    // ========== 通信模块 ==========
    let lastCheckTime = Date.now();
    let lastCharCount = 0;
    let accumulatedBuffer = "";
    const CHAR_THRESHOLD = 100;
    const CHECK_INTERVAL = 90000;
    
    // ========== 全局通信模块 ==========
    let socket; // 全局声明

    window.addEventListener('load', () => {
      // 初始化 Socket 连接（确保服务器地址正确）
      socket = io('http://localhost:3000'); 

      // 添加连接状态监听
      socket.on('connect', () => {
        console.log('Socket connected:', socket.id);
        socket.on('assistantResponse', (message) => {
          appendMessage('assistant', message);
        });
      });
      

      socket.on('disconnect', () => {
        console.log('Socket disconnected');
      });
    });

    // 初始化字符统计
    function initCharCounter() {
      const chatHistory = document.getElementById('chat-history');
      if (!chatHistory) return;
      lastCharCount = chatHistory.textContent.length;
    }

    // 定时检测函数
    function checkChatActivity() {
      const chatHistory = document.getElementById('chat-history');
      if (!chatHistory) return;
      const currentContent = chatHistory.textContent;
      const newChars = currentContent.slice(lastCharCount);
      accumulatedBuffer += newChars;
      lastCharCount = currentContent.length; // 关键修复：必须更新
      if (accumulatedBuffer.length >= CHAR_THRESHOLD) {
        console.log("🚀 触发传输:", accumulatedBuffer);
        socket.emit('td-generate', {
          timestamp: Date.now(),
          text: accumulatedBuffer
        });
        accumulatedBuffer = "";
      } else {
        console.log("⏳ 累积进度:", 
          `${accumulatedBuffer.length}/${CHAR_THRESHOLD}`,
          "最新内容:", newChars
        );
      }
    }

    // 定时器管理
    let checkTimer;
    function startCheckTimer() {
      checkTimer = setInterval(checkChatActivity, CHECK_INTERVAL);
      checkChatActivity(); // 立即执行一次
    }

    // 页面生命周期管理
    window.addEventListener('load', () => {
      initCharCounter();
      startCheckTimer();
    });

    document.addEventListener('visibilitychange', () => {
      if (document.hidden) {
        clearInterval(checkTimer);
      } else {
        startCheckTimer();
      }
    });

  </script>

  <script>

    // Check browser support for Web Speech API
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const debounce = (func, delay) => {
      let timeoutId;
      return (...args) => {
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => func(...args), delay);
      };
    };

    if (!SpeechRecognition) {
      alert("Sorry, your browser doesn't support speech recognition. Please use Chrome/Edge, etc.");
    } else {
      const recognition = new SpeechRecognition();
      recognition.continuous = true;       // keep listening until stopped
      recognition.interimResults = true;   // show real-time interim results
      recognition.lang = "en-US";          // language for recognition

      
      let interimBuffer = ""; // 添加这一行
      const chatHistory = document.getElementById('chat-history');
      const statusDiv   = document.getElementById('transcription-status');
      const micBtn      = document.getElementById('toggle-mic-btn');
      let listening = false;  // to track if mic is active

      // 修改后的appendMessage函数
      function appendMessage(sender, text) {
        const msgDiv = document.createElement('div');
        msgDiv.className = sender === 'user' ? 'user-message' : 'assistant-message';
        msgDiv.textContent = text;
        
        // 在添加元素前获取当前滚动状态
        const container = chatHistory;
        const wasAtBottom = container.scrollHeight - container.clientHeight <= container.scrollTop + 1;

        chatHistory.appendChild(msgDiv);

        // 使用双RAF确保DOM更新完成
        requestAnimationFrame(() => {
          requestAnimationFrame(() => {
            // 强制滚动到底部
            container.scrollTop = container.scrollHeight;
                
            // 如果当前不在底部，添加视觉提示
            if (!wasAtBottom) {
              container.style.boxShadow = 'inset 0 -5px 10px rgba(255,255,255,0.3)';
              setTimeout(() => {
                container.style.boxShadow = 'none';
              }, 500);
            }
          });
        });
      }

      micBtn.addEventListener('click', async () => {
        try {
          if (!listening) {
            // 显式请求麦克风权限
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
      
            recognition.start();
            micBtn.textContent = "🔴 Stop Listening";
            statusDiv.textContent = "Listening...";
            listening = true;
          } else {
            recognition.stop();
            micBtn.textContent = "🎙️ Start Listening";
            statusDiv.textContent = "";
            listening = false;
          }
        } catch (err) {
          console.error('麦克风访问错误:', err);
          statusDiv.textContent = "请允许麦克风访问";
          micBtn.textContent = "🎙️ Start Listening";
          listening = false;
        }
      });

      // 增加语音识别错误处理
      recognition.onerror = (event) => {
        console.error('识别错误:', event.error);
        if (event.error === 'not-allowed') {
          statusDiv.textContent = '请允许麦克风访问';
        }
        listening = false;
        micBtn.textContent = "🎙️ Start Listening";
      };

      // 修改后的变量
      let confirmedSegments = [];  // 存储所有已确认的段落
      let currentDraft = "";       // 当前临时草稿
      let silenceTimer = null;
      const SILENCE_TIMEOUT = 5000;

      // 统一提交函数
      //function commitFinalTranscript() {
        //if (pendingFinal.trim().length > 0) {
          //handleFinalTranscript(pendingFinal);
          //pendingFinal = "";
        //}
        //clearTimeout(silenceTimer);
        //}

      function handleFinalTranscript(rawText) {

        // 清洗步骤：
        let cleanText = rawText
          .replace(/(\b\w+\b)(\s+\1\b)+/gi, "$1") // 去重：将重复的单词合并
          .replace(/\s{2,}/g, " ")                // 合并多余空格
          .trim();
        
        // 2. 智能分段（防止句子截断）
        const sentences = cleanText.match(/[^.!?]+[.!?]*/g) || [];
        cleanText = sentences.join(" ").trim();

        if (cleanText) {
          appendMessage('user', cleanText);
          socket.emit('transcript', cleanText);
          statusDiv.textContent = "已提交 ✓";
        }
      }

      let debugCount = 0;

      recognition.onresult = (event) => {
    
        console.log(`处理结果 #${++debugCount}`, event);

        clearTimeout(silenceTimer); // 必须首先清除旧计时器

        let hasNewFinal = false;
    
        // 处理所有结果
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          const text = result[0].transcript.trim();
    
          if (result.isFinal) {
            // 最终结果：存入历史段落
            confirmedSegments.push(text);
            hasNewFinal = true;
          } else {
            // 临时结果：更新当前草稿
            currentDraft = text;
          }
        }

        // 构建完整内容
        let fullText = "";

        if (confirmedSegments.length > 0) {
          fullText = confirmedSegments.join(". ") //+ (currentDraft ? ` ${currentDraft}` : "");
        } else {
          fullText = currentDraft;
        }

        // 更新显示
        statusDiv.textContent = hasNewFinal 
          ? `已确认段落: ${confirmedSegments.join(" | ")}`
          : currentDraft 
            ? `输入中: ${currentDraft}`
            : "";

        const debouncedHandle = debounce((text) => {
          handleFinalTranscript(text);
          confirmedSegments = [];
          currentDraft = "";
        }, 300); // 300ms防抖窗口

        silenceTimer = setTimeout(() => debouncedHandle(fullText), 5000);
      };

      // Restart recognition automatically if it stops (for continuous listening)
      recognition.onend = () => {
        if (listening) {
          // If the mic is still supposed to be on, restart listening (user paused speaking)
          recognition.start();
        }
      };

      // 需要修改的错误处理代码段
      recognition.onerror = (err) => {
        console.error("Speech recognition error:", err);
        clearTimeout(silenceTimer);
    
        // 新增错误类型过滤
        const ignorableErrors = [
          'no-speech',         // 无语音输入
          'audio-capture',     // 音频捕获问题
          'network'            // 网络错误
        ];

        if (listening) {
          // 对可忽略错误不显示提示
          if (!ignorableErrors.includes(err.error)) {
            statusDiv.textContent = "⚠️ Mic error, restarting...";
          }
        
          // 优化重启策略
          const retry = () => {
            recognition.stop();  // 先正常停止
            setTimeout(() => {
              recognition.start().catch(error => {
                console.log('重启失败:', error);
              });
            }, 500);
          };
        
          // 根据错误类型处理
          switch(err.error) {
            case 'no-speech':
              // 无语音时不重启
              break;
            case 'network':
              retry();
              break;
            default:
              setTimeout(retry, 1000);
          }
        }
      };

      // Receive AI assistant responses from the server and display them
      //socket.on('assistantResponse', (message) => {
        //appendMessage('assistant', message);
      //});
    }

  </script>

<script>
  // Connect to TouchDesigner’s signaling server via WebSocket
  const ws = new WebSocket('ws://localhost:877');  // Use actual IP if needed
  let pc;  // RTCPeerConnection

  ws.onerror = err => console.error('WebSocket error:', err);
  ws.onopen = () => {
    console.log('Signaling WebSocket connected');
    // Create RTCPeerConnection once WS is ready
    const config = { iceServers: [{ urls: "stun:stun.l.google.com:19302" }] };
    pc = new RTCPeerConnection(config);
    
    // When a remote track arrives, attach it to the video element
    pc.ontrack = event => {
      console.log('Remote track received');
      const videoEl = document.querySelector('.streamVideo');
      videoEl.srcObject = event.streams[0];
      // 延时调用 play()，确保没有其他 load 操作干扰
      setTimeout(() => {
        videoEl.play().catch(err => console.error('Video play error:', err));
      }, 100);
    };
    
    // Forward local ICE candidates to TouchDesigner via WebSocket
    pc.onicecandidate = event => {
      if (event.candidate) {
        ws.send(JSON.stringify({
          signalingType: "Ice",
          content: {
            sdpCandidate: event.candidate.candidate,
            sdpMLineIndex: event.candidate.sdpMLineIndex,
            sdpMid: event.candidate.sdpMid
          }
        }));
      }
    };
  };

  // Handle signaling messages from TouchDesigner
  ws.onmessage = async (message) => {
    const msg = JSON.parse(message.data);
    console.log('Signaling message received:', msg);
    switch(msg.signalingType) {
      case "Offer":
        console.log("Received offer from TD");
        await pc.setRemoteDescription({ type: "offer", sdp: msg.content.sdp });
        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
        // Send answer back to TD
        ws.send(JSON.stringify({ signalingType: "Answer", content: { sdp: answer.sdp } }));
        break;
      case "Answer":
        console.log("Received answer from TD");
        await pc.setRemoteDescription({ type: "answer", sdp: msg.content.sdp });
        break;
      case "Ice":
        console.log("Received ICE candidate from TD");
        const cand = msg.content;
        await pc.addIceCandidate(new RTCIceCandidate({
          candidate: cand.sdpCandidate, 
          sdpMLineIndex: cand.sdpMLineIndex, 
          sdpMid: cand.sdpMid 
        }));
        break;
      case "Clients":
        console.log("Signaling server client list update:", msg.content);
        break;
    }
  };
</script>

</body>

</html>